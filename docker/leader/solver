#!/usr/bin/env python3
import json
import logging
import os
import subprocess
import sys
import threading
import glob

logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

def reverse_function(x):
    return x[::-1]


class Runner:
    def __init__(self, request_directory: str):
        self.logger = logging.getLogger("Runner")
        self.logger.setLevel(logging.INFO)
        self.request_directory = request_directory
        os.environ['PYTHONUNBUFFERED'] = "1"

    def process_stream(self, stream, str_name, file_handle):
        line = stream.readline()
        while line != "":
            self.logger.info(f"{str_name}: {line}")
            file_handle.write(line)
            line = stream.readline()

    def run(self, cmd: list, is_append=False):
        self.logger.info("Running command: %s", str(cmd))
        
        stdout_target_loc = os.path.join(self.request_directory, "stdout.log")
        stderr_target_loc = os.path.join(self.request_directory, "stderr.log")
        
        access = "a" if is_append else "w"

        with open(stdout_target_loc, access) as stdout_handle:
            with open(stderr_target_loc, access) as stderr_handle:
                proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                    universal_newlines=True, start_new_session=True)
                stdout_t = threading.Thread(target = self.process_stream, args=(proc.stdout, "STDOUT", stdout_handle))
                stderr_t = threading.Thread(target = self.process_stream, args=(proc.stderr, "STDERR", stderr_handle))
                stdout_t.start()
                stderr_t.start()
                return_code = proc.wait()
                stdout_t.join()
                stderr_t.join()
       
        return {
            "stdout": stdout_target_loc,
            "stderr": stderr_target_loc,
            "return_code": return_code,
            "output_directory": self.request_directory
        }


    def get_input_json(self):
        input = os.path.join(self.request_directory, "input.json")
        with open(input) as f:
            return json.loads(f.read())
    
    def create_hostfile(self,ips, request_dir):
        hostfile_path = os.path.join(request_dir, 'combined_hostfile')
        with open(hostfile_path, 'w+') as f:
            for ip in ips:
                f.write(f'{ip} slots=4') # Cloud track
                # f.write(f'{ip} slots=16') # Parallel track
                f.write('\n')
            return hostfile_path

    def get_command(self, input_json):
        problem_path = input_json.get("problem_path")
        worker_node_ips = input_json.get("worker_node_ips", [])
        
        combined_hostfile = self.create_hostfile(worker_node_ips, self.request_directory)

        run_list = ["/competition/run_mallob.sh"]
        run_list.append(combined_hostfile)
        run_list.append(problem_path)

        return run_list

    # /competition/compose-proofs /dimacs/sample/simple.cnf /logs/combined_hostfile/combined.lrat /logs/combined_hostfile/0/proof.0.frat /logs/combined_hostfile/1/proof.1.frat /logs/combined_hostfile/3/proof.2.frat /logs/combined_hostfile/2/proof.3.frat
    def determine_proof_files(self): 
        rootdir = '/logs/processes'
        proof_files = []
        for path in glob.glob(f'{rootdir}/*/proof.*.frat'):
            print(f"An expected proof file path is: {path}")
            proof_files.append(path)

        # silly trick so that the proof file numbers are 'first' in the sort.
        reversed_files = [reverse_function(str) for str in proof_files]
        reversed_files.sort()
        proof_files = [reverse_function(str) for str in reversed_files]

        print(f"The list of proof files is: {proof_files}")
        return proof_files


    def get_combine_command(self, input_json):
        problem_path = input_json.get("problem_path")

        proof_files = self.determine_proof_files()
        args = ['/compose-proofs', problem_path, '/logs/processes/combined.lrat']
        args.extend(proof_files)
        return args

    def get_check_command(self, input_json):
        problem_path = input_json.get("problem_path")
        # run_list = ["echo", f"Would be running /lrat-check /logs/processes/combined.lrat"]
        args = ['/lrat-check', problem_path, '/logs/processes/combined.lrat']
        return args

class MallobParser:
    @staticmethod
    def get_result(output_file):
        """
        TODO: Participants should replace this with something more robust for their own solver!
        """
        with open(output_file) as f:
            raw_logs = f.read()
            if "s UNSATISFIABLE" in raw_logs:
                return "UNSATISFIABLE"
            elif "s SATISFIABLE" in raw_logs:
                return "SATISFIABLE"
            elif "result SAT" in raw_logs:
                return "SATISFIABLE"
            elif "result UNSAT" in raw_logs:
                return "UNSATISFIABLE"
            elif "[ERROR]" in raw_logs:
                return "ERROR"
            else:
                return "UNKNOWN"


if __name__ == "__main__":
    
    request_directory = sys.argv[1]
    runner = Runner(request_directory)
    runner.logger.info("Hello from /competition/solver")
    
    input_json = runner.get_input_json()
    cmd = runner.get_command(input_json)
    
    runner.logger.info("Running solver ...")
    
    output = runner.run(cmd)
    result = MallobParser.get_result(output["stdout"])
    runner.logger.info(f"RESULT: {result}")

    # proof check
    if (result == "UNSATISFIABLE"):
        combine_cmd = runner.get_combine_command(input_json)
        runner.logger.info(f"Running combiner with {combine_cmd}")
        combiner_result = runner.run(combine_cmd, True)
        if combiner_result["return_code"]:
            runner.logger.info(f"Combiner return code was non-zero ({combiner_result.return_code}).  Returning 'ERROR'.")
            result = "ERROR"  
        else:
            check_cmd = runner.get_check_command(input_json)
            runner.logger.info(f"Running proof checker with {check_cmd}")
            checker_result = runner.run(check_cmd, True)
            if checker_result["return_code"]:
                runner.logger.info(f"Checker return code was non-zero ({checker_result.return_code}).  Returning 'ERROR'.")
                result = "ERROR"  
            else:
                runner.logger.info(f"Checker return code was zero.  Check successful!")

    # clean up.
    runner.run(['/competition/cleanup'], True)

    solver_output = {
        "return_code": output["return_code"],
        "result": result,
        "artifacts": {
            "stdout_path": output["stdout"],
            "stderr_path": output["stderr"]
        }
    }
    
    with open(os.path.join(request_directory, "solver_out.json"), "w+") as f:
        f.write(json.dumps(solver_output))
